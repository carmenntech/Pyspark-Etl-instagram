{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a346ad62-ce26-4fef-8f26-b4cbd695ba62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- comentario: string (nullable = true)\n",
      " |-- like: string (nullable = true)\n",
      " |-- fecha: string (nullable = false)\n",
      " |-- tipopublicacion: string (nullable = true)\n",
      " |-- oldvisualizaciones: string (nullable = true)\n",
      " |-- visualizaciones: string (nullable = true)\n",
      " |-- titulo: string (nullable = false)\n",
      "\n",
      "+--------------------+---------------------+\n",
      "|engagement_like     |engagement_comentario|\n",
      "+--------------------+---------------------+\n",
      "|NULL                |NULL                 |\n",
      "|0.028102692548528492|0.002654978083907326 |\n",
      "|0.01385707741639945 |1.7178195144296838E-4|\n",
      "|0.026531818480330992|8.865830432783871E-4 |\n",
      "|0.03543831601385558 |0.0019539923616662225|\n",
      "|0.016722408026755852|8.361204013377926E-4 |\n",
      "|0.014875319586944252|6.640767672742969E-4 |\n",
      "|0.012505709877873254|6.894946865815716E-5 |\n",
      "|0.02140585694622431 |0.0016612084104608666|\n",
      "|0.025825645641141027|0.002300057501437536 |\n",
      "|0.028683983749846115|0.003988674135171734 |\n",
      "|0.021956856702619414|0.002274561596595495 |\n",
      "|0.015875275859614152|0.0037255879072637097|\n",
      "|0.03093782048847191 |0.0031906407870247273|\n",
      "|0.026310335639353   |4.6383562454973404E-4|\n",
      "|0.010047679466811931|1.5702528203970025E-4|\n",
      "|0.02022769628662348 |2.282034053019258E-4 |\n",
      "|0.016496983408748115|0.0011940673705379589|\n",
      "|0.028282175204818957|2.6876266787001556E-4|\n",
      "|0.021705459708299273|0.0017424600955126275|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode, col, regexp_replace, regexp_extract_all,  expr, array_join, trim, regexp_extract, concat_ws\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark\n",
    "import collections\n",
    "import re\n",
    "from pyspark.sql.types import IntegerType, DateType, StringType, StructType, StructField\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"EjemploPySpark\").getOrCreate()\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "file = 'data_user_reels_claudianicolasa.csv'\n",
    "\n",
    "lines = spark.sparkContext.textFile(file)\n",
    "\n",
    "'''\n",
    "El csv tiene el problema de que un campo esta ocupando una o varias filas del csv\n",
    "es_incompleta y unir_lineas_incompletas son dos metodos para solventar este problema\n",
    "es_incompleta para comprobar si el campo usa mas de una linea\n",
    "unir_lineas_incompletas para joinear esas lineas\n",
    "'''\n",
    "\n",
    "# Función para eliminar comas dentro de comillas dobles en una línea CSV\n",
    "def eliminar_comas_entre_comillas(line):\n",
    "    # Usamos una expresión regular que encuentra cualquier cosa entre comillas dobles\n",
    "    # y luego eliminamos las comas que están dentro de ese texto\n",
    "    return re.sub(r'\\\"(.*?)\\\"', lambda match: match.group(0).replace(\",\", \"\"), line)\n",
    "\n",
    "\n",
    "# Función para verificar si la línea está incompleta\n",
    "def es_incompleta(line):\n",
    "    # Verifica si la línea contiene un número impar de comillas dobles\n",
    "    return line.count('\"') % 2 != 0\n",
    "\n",
    "# Acumulamos las líneas hasta que tengamos una línea completa (con un número par de comillas)\n",
    "def unir_lineas_incompletas(rdd):\n",
    "    acumulado = []\n",
    "    resultados = []\n",
    "\n",
    "    for line in rdd.collect():\n",
    "        acumulado.append(line)\n",
    "        # Si la línea completa el conjunto de comillas\n",
    "        if not es_incompleta(\" \".join(acumulado)):\n",
    "            # Unimos las líneas acumuladas y las añadimos al resultado\n",
    "            resultados.append(\" \".join(acumulado))\n",
    "            acumulado = []\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "# Unir las líneas mal formadas en el RDD\n",
    "lineas_corregidas = spark.sparkContext.parallelize(unir_lineas_incompletas(lines))\n",
    "\n",
    "\n",
    "# Aplicamos la función a cada línea corregida para eliminar las comas entre comillas\n",
    "rdd_sin_comas = lineas_corregidas.map(eliminar_comas_entre_comillas)\n",
    "\n",
    "# Ahora convertimos cada línea en una lista de columnas usando split por comas\n",
    "rdd_estructurado = rdd_sin_comas.map(lambda line: line.split(\",\"))\n",
    "\n",
    "\n",
    "# Creamos el schema del dataframe\n",
    "\n",
    "esquema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"comentario\", StringType(), True),\n",
    "    StructField(\"like\", StringType(), True),\n",
    "    StructField(\"fecha\", StringType(), False),\n",
    "    StructField(\"tipopublicacion\", StringType(), True),\n",
    "    StructField(\"oldvisualizaciones\", StringType(), True),\n",
    "    StructField(\"visualizaciones\", StringType(), True),\n",
    "    StructField(\"titulo\", StringType(), False)\n",
    "])\n",
    "\n",
    "     \n",
    "# Convertimos el RDD en DataFrame usando toDF y asignamos nombres de columnas\n",
    "df = spark.createDataFrame(rdd_estructurado, schema=esquema)\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "#PROCEDEMOS A TRANSFORMAR ALGUNAS COLUMNAS\n",
    "\n",
    "#Creamos una sola columna para las views\n",
    "df = df.withColumn(\"totalViews\", df.oldvisualizaciones + df.visualizaciones)\n",
    "\n",
    "#En cuanto al titulo lo dividimos en la parte de hastag y el resto\n",
    "df = df.withColumn(\"titulopublicacion\", split(df[\"titulo\"], \"#\").getItem(0)) \n",
    "df = df.withColumn(\"hashtagtodos\", regexp_replace(df[\"titulo\"], df[\"titulopublicacion\"], \"---\"))\n",
    "#df.select(\"hashtagtodos\").show(truncate=False)\n",
    "#df.select(\"titulopublicacion\").show(truncate=False)\n",
    "    #.withColumn(\"hastag2\", split(df[\"titulo\"], \"#\").getItem(1))\\\n",
    "      \n",
    "#creamos nuevas columnas en funcion de la fecha de publicacion -> año, mes, dia_semana, hora\n",
    "df = df.withColumn(\"fecha_anio\", split(df[\"fecha\"], \"-\").getItem(0)) \n",
    "df = df.withColumn(\"fecha_mes\", split(df[\"fecha\"], \"-\").getItem(1)) \n",
    "df = df.withColumn(\"fecha_hora\", split(df[\"fecha\"], \" \").getItem(1)) \n",
    "\n",
    "df = df.withColumn(\"fecha_timestamp\", F.to_timestamp(F.col(\"fecha\"), \"yyyy-MM-dd HH:mm:ssXXX\"))\n",
    "df = df.withColumn(\"fecha_hora_dia_semana\", F.date_format(F.col(\"fecha_timestamp\"), \"EEEE\"))\n",
    "\n",
    "#Creamos dos nuevas columnas para el engagement por like y por comentario \n",
    "df = df.withColumn(\"engagement_like\", df.like / df.totalViews)\n",
    "df = df.withColumn(\"engagement_comentario\", df.comentario / df.totalViews)\n",
    "\n",
    "\n",
    "df.select(\"engagement_like\", \"engagement_comentario\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a205b27-c297-44ae-a0ff-fc99237efad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4bf3f-20df-4118-b340-9b2db92306a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4e3aa-0e05-4b31-9464-47fc90705056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0ddd4-92de-4d38-b67c-bb07b22aa53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
