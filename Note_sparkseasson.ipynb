{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "\r\n",
        "from pyspark.sql.functions import split, explode, col, regexp_replace\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "import pyspark\r\n",
        "import collections\r\n",
        "\r\n",
        "# Crear una sesión de Spark\r\n",
        "spark = SparkSession.builder.appName(\"EjemploPySpark\").getOrCreate()\r\n",
        "\r\n",
        "# Ruta al archivo CSV\r\n",
        "file = 'abfss://fsinsta@lakeinsta.dfs.core.windows.net/data-user-reels-albisites.csv'\r\n",
        "\r\n",
        "lines = spark.sparkContext.textFile(file)\r\n",
        "\r\n",
        "#rdd_reemplazado = lines.map(lambda x: x.replace('\"', ' '))\r\n",
        "# Función para concatenar valores entre comillas\r\n",
        "\r\n",
        "# Aplicar la función a cada fila del RDD\r\n",
        "#rdd_concatenado = lines.map(concatenar_filas)\r\n",
        "\r\n",
        "rdd_split = lines.map(lambda x: x.split(';\"'))\r\n",
        "\r\n",
        "# Recoger y mostrar los resultados\r\n",
        "results = rdd_split.collect()\r\n",
        "print(results)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}