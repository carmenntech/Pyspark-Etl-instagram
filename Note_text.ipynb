{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "\r\n",
        "from pyspark.sql.functions import col, split\r\n",
        "from pyspark.sql.types import IntegerType, DateType\r\n",
        "\r\n",
        "file = 'abfss://fsinsta@lakeinsta.dfs.core.windows.net/data_user_reels_claudianicolasa.csv'\r\n",
        "\r\n",
        "#Creamos un dataframe con el fichero del s3 e inferimos su esquema \r\n",
        "df = (spark.read.format(\"csv\")\r\n",
        "     .option(\"header\", \"true\")\r\n",
        "     .option(\"inferSchema\", \"true\")\r\n",
        "     .load(file))\r\n",
        "\r\n",
        "\r\n",
        "#Casteamos algunas de las columnas que no se han inferido bien el tipo\r\n",
        "df = df.withColumn(\"comentario\", col(\"comentario\").cast(IntegerType()))\r\n",
        "df = df.withColumn(\"like\", col(\"like\").cast(IntegerType()))\r\n",
        "df = df.withColumn(\"oldvisualizaciones\", col(\"oldvisualizaciones\").cast(IntegerType()))\r\n",
        "df = df.withColumn(\"visualizaciones\", col(\"visualizaciones\").cast(IntegerType()))\r\n",
        "df = df.withColumn(\"fecha\", col(\"fecha\").cast(DateType()))\r\n",
        "\r\n",
        "df.printSchema()\r\n",
        "\r\n",
        "df = df.withColumn(\"titulopublicacion\", split(df[\"titulo\"], \"#\").getItem(0)) \\\r\n",
        "       .withColumn(\"hastag\", split(df[\"titulo\"], \"#\").getItem(1))\r\n",
        "\r\n",
        "df = df.withColumn(\"totalViews\", df.oldvisualizaciones + df.visualizaciones)\r\n",
        "\r\n",
        "display(df.limit(10))\r\n",
        "display(df.where(df.comentario>1000))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "statement_id": -1,
              "statement_ids": [],
              "state": "finished",
              "livy_statement_state": null,
              "spark_jobs": null,
              "session_id": null,
              "normalized_state": "finished",
              "queued_time": "2024-10-17T14:01:07.825823Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2024-10-17T14:01:07.9233497Z",
              "parent_msg_id": "85aa8fa1-3eb9-4aab-9e6f-a522b3854a29"
            },
            "text/plain": "StatementMeta(, , -1, Finished, , Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "LIVY_JOB_TIMED_OUT",
          "evalue": "Livy session has failed. Session state: Dead. Error code: LIVY_JOB_TIMED_OUT. Job failed during run time with state=[dead]. Source: Unknown.",
          "traceback": [
            "LIVY_JOB_TIMED_OUT: Livy session has failed. Session state: Dead. Error code: LIVY_JOB_TIMED_OUT. Job failed during run time with state=[dead]. Source: Unknown."
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}